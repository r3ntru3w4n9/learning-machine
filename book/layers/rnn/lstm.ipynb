{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Long short term memory is often abbreviated as **LSTM**.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are LSTMs?\n",
    "\n",
    "LSTM is a special kind of recurrent layer. A human brain use both long-term memory and short-term memory to remember things, and LSTM is that idea in neural network. Its construct allows some input to be unprocessed by the layer (long term memory) while processing a portion of the input (short term memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use LSTMs?\n",
    "\n",
    "Compare to vanilla RNN (the one introduced in the privious section), almost always. Vanilla RNNs are too difficult to train because of gradient issues, while because LSTM allow some input to escape processing, it helps tremendously in that regard."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
